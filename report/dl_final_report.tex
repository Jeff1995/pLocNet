%!TEX program = xelatex
\documentclass[a4paper,UTF8]{article}
\usepackage[unicode=true,colorlinks,urlcolor=blue,linkcolor=blue,citecolor=red,bookmarksnumbered=true]{hyperref}
\usepackage{latexsym,amssymb,amsmath,amsbsy,amsopn,amstext,amsthm,amsxtra,color,multicol,bm,calc,ifpdf}
\usepackage{ctex}
\usepackage{graphicx}
\usepackage{diagbox}   % 绘制表格斜线
\usepackage{enumerate}
\usepackage[numbers,authoryear]{natbib}
\usepackage{fancyhdr}
\usepackage{subfig}
\usepackage{listings}
\usepackage{multirow}
\usepackage{makeidx}
\usepackage{xcolor} 
\usepackage{float}
\usepackage{geometry}
\geometry{a4paper,scale=0.7}
% \geometry{a4paper,left=2cm,right=2cm,top=1cm,bottom=1cm}

\graphicspath{{figures/}}  % 设置图片搜索路径

\newcommand\diff{\,{\mathrm d}}     % 定义微分 d
\newcommand{\p}[3]{\frac{\partial^{#1}#2}{\partial{#3}^{#1}}}  % 定义求偏导算子

\renewcommand\contentsname{Contents}
\renewcommand\refname{References}
\renewcommand\figurename{Figure}
\renewcommand\tablename{Table}


\begin{document}
\title{
	\includegraphics[width = 0.85\textwidth]{pku.pdf}\\
	\vspace{2em}
	\textbf{\huge{深度学习算法与应用期末作业报告}}\\
	\vspace{1em}
	\large{题目\ \underline{\makebox[26em]{基于图卷积神经网络的蛋白亚细胞定位预测}}}
}

\author{姓名\ \underline{\makebox[24em]{曹智杰，李响，郭宇航}}\\
	学号\ \underline{\makebox[24em]{1701110560，1701111447，1701110049}}\\
	学院\ \underline{\makebox[24em]{生命科学学院，前沿交叉学科研究院，数学科学学院}}\\
	专业\ \underline{\makebox[24em]{生物信息学，整合生命科学，统计学}}
}

\date{2018 年 8 月 30 日}


\maketitle
\thispagestyle{empty}

\newpage


\tableofcontents

\newpage
\section*{\heiti{\zihao{4}摘\quad\quad 要}}
\begin{abstract}
	\quad 本文试图通过建立统计模型对中国股市的“特别处理”政策进行分析，即根据上市企业当年的财务报表情况对其之后是否非会被“特别处理”进行预测评估。首先我们应用GLM即广义线性模型对数据进行分析，欠佳的结果反映出该数据并非来自于参数模型；之后我们采用半参数方法即Single-Index模型对数据进行拟合，得到了同参数模型相比较好的结果；再之后我们将问题看作一个分类问题，运用Kernel-SVM方法对数据进行分类处理，得到了比之前的模型更满意的结果。 \\
	\noindent{\heiti 关键字:} Single-Index模型; 股票预测; 分类问题.
\end{abstract}\thispagestyle{empty}
\newpage{}
\section{问题背景}
\subsection{图卷积模型}
许多重要的现实世界数据集以图形或网络的形式出现：如社交网络，知识图谱，蛋白质交互网络，万维网等。 然而，直到最近人们也很少关注神经网络模型对这种结构化数据集的应用。\\

推广完善的神经模型（如RNN或CNN）来处理任意结构化图形是一个具有挑战性的问题。最近的一些论文介绍了特定问题的网络架构（例如Duvenaud等人，NIPS 2015; Li等人，ICLR 2016; Jain等人，CVPR 2016），其他人则利用谱图理论中已知的图形卷积（Bruna et例如，ICLR 2014; Henaff等，2015）定义用于多层神经网络模型的参数化滤波器，类似于我们所熟知和喜爱的“经典”CNN。最近的工作重点是弥合快速启发式的算法和高昂的计算复杂度。 Defferrard等人（NIPS 2016）使用具有自由参数的切比雪夫多项式在谱域中近似平滑滤波器，所述自由参数在类似神经网络的模型中学习。它们在常规域（如MNIST）上取得令人信服的结果，与简单的2D CNN模型非常接近。在Kipf＆Welling（ICLR 2017）中，我们采用了一种类似的方法，从谱图卷积的框架开始，然后引入简化（我们将在后面的文章中介绍），在许多情况下可以兼得显著加快训练时间和更高的预测准确性两者，在许多基准图数据集上达到最先进的分类结果。\\

目前，大多数图形神经网络模型具有一些共同的通用架构。 我将这些模型称为图形卷积网络（GCN）; 卷积，因为滤波器参数通常在图中的所有位置（或其子集，如Duvenaud等，NIPS 2015中）共享。\\

对于这些模型，目标是在图形$G=(V,E)$上学习信号/特征的函数;输入如下：\\

每个节点i的特征描述xi; 总结在N×D特征矩阵X中（N：节点数，D：输入特征数）
矩阵形式的图结构的代表性描述; 通常以邻接矩阵A（或其某些功能）的形式
并产生节点级输出Z（N×F特征矩阵，其中F是每个节点的输出特征数）。 图形级输出可以通过引入某种形式的池操作来建模（参见，例如Duvenaud等，NIPS 2015）。

然后可以将每个神经网络层写为非线性函数
H（L + 1）= F（H（L）的A），
H（0）= X且H（L）= Z（或图形级输出为z），L为层数。 然后，具体模型的区别仅在于如何选择f（⋅，⋅）和参数化。

\[ H^{(l+1)} = \sigma \left( \hat{D}^{-\frac{1}{2}} \hat{A} \hat{D}^{-\frac{1}{2}} H^{(l)}W^{(l)}\right)\]




由于$y_{i}$是0-1变量，故我们首先考虑用GLM对数据进行拟合，假设$y_{i}$服从参数为$p_{i}$的伯努利分布，即
$$f(y_i,p_i,n_i)=exp\left\{ \left(y_{i}\log \frac{p_{i}}{1-p_{i}} -\left(-\log (1-p_{i}) \right)\right)/\left(\frac{1}{n_i} \right)+\log \binom{n_i}{n_iy_{i}} \right\} $$ 

假设$\mathbb{E}y_{i}$即$p_{i}$经过连接函数$g(\cdot)$变换后与协变量$x_{i}$呈线性关系，即$ g(p_{i})=\eta_{i}=x_{i}'\beta  $.
我们可以选取以下函数作为连接函数
\begin{itemize}
	\item Logistic Link: $$g(x)=\log \frac{\mu}{1-\mu}\quad\quad p_{i}=\frac{e^{\eta_{i}}}{1+e^{\eta_{i}}} $$
	\item Probit Link: $$g(x)=\Phi^{-1}(x) \quad\quad p_{i}=\Phi(\eta_{i})  $$
	\item C log-log Link: $$\log(-\log(1-\mu)) \quad\quad p_{i}=1-exp\{  -e^{\eta_{i}}\}$$
\end{itemize}

这三类连接函数在$p_{i}\in (0.1,0.9)$时差别不大，但是此问题的数据中被“ST”的样本数目较少，即$p_{i}$的值较小，故在模型假设正确的情况下连接函数的选择可能会影响模型的拟合结果。\\

采用 Fisher-Scoring 或者 Newton-Raphson 算法, 我们可以得到 $\beta$的估计值$\hat{\beta}$, 之后我们可以得到 $\hat{\eta_{i}}$ 和 $\hat{p_{i}}$。我们想估计的 $y_{i}$ 是一个取值为0或者1的随机变量， 所以我们要把介于0，1之间的$\hat{p_{i}}$转换为0或1。\\

我们可以选取一个临界值 $\tau $ 然后令：
$$ \hat{y_{i}} = \left\{
\begin{array}{rcl}
1     &      & {\text{if} \quad \hat{p_{i}} \geq \tau}\\
0     &      & {\text{if} \quad \hat{p_{i}}<\tau}\\
\end{array} \right. $$

对于临界值$\tau $的选取，我们可以采用如下两种方法。
\begin{enumerate}[1.]
	\item 简单的选取 $\tau$ 等于0.5;
	\item 采用同时控制第一类错误概率和第二类错误概率的方法根据样本数据得到$\tau$.
\end{enumerate}

由此得到的拟合结果和分析如下：
\begin{enumerate}[(1)]
	\item 648个属于0类别的企业分类结果正确的有647个，36个属于1类别的企业分类正确的有1个；
	\item 采用三种连接函数得到的结果无差异；
	\item 降低临界值$\tau$，会小幅度提高把属于1类别的企业分类正确的数目，但是同时会显著提升0分类的错误的数目。
\end{enumerate}

鉴于以上三点，说明GLM模型并不适用于本数据。于是，我们接下来考虑半参数的Single Index模型。

\subsection{蛋白质亚细胞定位}

蛋白质亚细胞定位预测是一类重要的生物信息学问题。相关的预测工具通常以蛋白质本身的氨基酸序列信息为输入，输出预测的蛋白质细胞亚定位。它可以提供蛋白质功能和基因注释的信息，辅助药物靶点的识别。
现有的蛋白质亚细胞定位预测工具通常是从蛋白质的氨基酸序列中提取出一些特征，将序列转化为数值向量，再用机器学习模型进行预测。如目前最广泛使用的适用于真核生物蛋白质的WoLF PSORT软件，将蛋白质的氨基酸组成作为特征，以k-nearest neighbor算法给出与输入蛋白最相似的32个蛋白质的细胞亚定位。（这里要插入一篇引用）我们认为，现有的预测工具还具有一定的提升空间。首先，提取的序列特征未必能充分反映蛋白质与训练任务相关的性质。其次，目前的预测都仅仅使用了蛋白质本身的信息，而没有考虑到蛋白质间的相互作用。考虑到蛋白质发生相互作用必须在空间上接近，蛋白质的相互作用信息很有可能可以提高亚细胞定位的预测准确度。因此，我们希望用神经网络将蛋白质序列embedding为数值向量，与蛋白质的相互作用信息结合，建立图卷积神经网络模型来进行蛋白质亚细胞定位的预测，以期能达到更好的预测功效。
（TODO: 是不是要加一下什么是蛋白，蛋白由20种氨基酸连接组成啥的，还有什么是亚细胞定位，序列与亚细胞定位的关系（motif，NLS, NES……）？）



\subsection{Single Index 模型}
为了更好的预测被特别处理的可能性，我们采用半参数的方法来建立回归模型，进而得出因变量与协变量之间关系。模型的基本假设如下：

考虑 Binary Choice Model：
$$ Y = \left\{
\begin{array}{rcl}
1     &      & {if \quad Y_i^{*}>0}\\
0     &      & {if \quad Y_i^{*}\leq0}\\
\end{array} \right. $$

其中$Y_i^{*}$是中间变量，与协变量相关。
\[ Y_i^{*}=\alpha+X'\beta+\epsilon_i \]

假设$F_\epsilon$是随机项$\epsilon$的累积分布函数，则有：
\begin{align*}
E(Y|x)&=P(Y=1|x)=P(Y_i^{*}>0|x)\\
&=P(\epsilon_i>-(\alpha+X'\beta))=1-F_\epsilon(-(\alpha+X'\beta))\\
&=m(\alpha+X'\beta)
\end{align*}

值得说明的是，$F_\epsilon$未知，是我们模型待估计的参量，以上模型由协变量的线性组合复合一个函数组成，称为半参数 single index 模型。

更一般的半参数模型有如下形式：
\[  Y=g(x'\beta_0)+u  \]
\[ E(u|X)=0 \]

对于我们用到的半参数Binary Choice Model模型，有：
\[ E(Y|x)=g(x'\beta_0)=m(\alpha+X'\beta) \]
$$i.e. \qquad g(t)=m(\alpha+t)$$
其中$\beta$是未知的参数，$g()$是连接函数，需要我们去估计。\\

根据高级计量经济专题讲义的内容，关于参数的估计方法大致有两种思路:
\begin{itemize}
	\item 当g的形式已知时，可以很简单的用非线性回归来给出$\beta$的估计。进一步，此时的问题即是广义线性模型的范畴，我们可以用迭代算法给出结果，并做出统计推断和分析解释。
	\item 当g的形式未知时，不妨用kernel methods来估计$g()$的形式。估计的方法有Ichimura’s Estimator, Average Derivative estimator 等。
	\item 对于Binary Choice Model, Klein \& Spady’s Estimator, Lewbel’s Estimator, Manski’s Maximum Score Estimator, Horowitz’s Smoothed Maximum Score Estimation, Han’s Maximum Rank Estimator 等方法均有可能派的上用场。
\end{itemize}

在此例中，我们采用 Klein \& Spady’s Estimator， 即
$$\hat{\beta}_{KS}= \arg \max \mathbb{L} (\beta) $$
$$\mathbb{L} (\beta)=\sum (1-Y_{i})\ln (1-\hat{g}(x_{i}\beta))+\sum Y_{i}\ln (\hat{g}(x_{i}\beta)) $$

通过R中的np包可以实现上述算法，若把所有7个变量放入模型中，得到的结果和分析如下：
\begin{enumerate}[(1)]
	\item 若取$\tau=0.5$，648个0分类正确的有648个，36个1分类正确的有3个，总体正确率95.17\%
	\item ASSET与SHARE的系数并不显著 
\end{enumerate}

若改变临界值 $\tau$,可提高将1分类正确的数目，并且同时由此带来0错误的数目的略有增加，但是相较GLM结果相比有很大的提升，结果如表 \ref{tab:tab1} 所示。\\
\begin{table}[h]
	\centering
	\caption{Full Single Index Model}\label{tab:tab1}
	\begin{tabular}{|l|c|c|c|c|c|}
		\hline
		$\tau$ &  0.5 & 0.4 & 0.3 & 0.2& 0.1 \\
		\hline
		\text{Correct} 1 & 3  & 3 &  4 & 10 &24    \\ \hline
		\text{Correct} 0 & 648 & 648 & 647  & 634 & 557   \\ \hline
		\text{Wrong}  1 & 33  & 33 & 32  & 26 &  12  \\ \hline
		\text{Wrong} 0 & 0  & 0 & 1  & 14 &  91  \\ \hline
		\text{TCR} & 95.17\%  &  95.17\%  &  95.17\%  & 94.15\% &  84.94\%  \\
		\hline 
	\end{tabular}
\end{table}

考虑到上述模型中ASSET与SHARE的系数并不显著，我们把这两个协变量从模型中剔除，再次求解Single-Index模型，得到的结果和分析如下：
\begin{enumerate}[(1)]
	\item 若取$\tau=0.5$，648个0分类正确的有648个，36个1分类正确的有4个，总体正确率95.32\%，同全模型相比有一定的提升;
	\item 采用同上相同的方法，若改变临界值 $\tau$, ，得到的结果如下表 \ref{tab:tab2} 所示：
	\begin{table}[!htb]
		\centering
		\caption{Reduced Single Index Model}\label{tab:tab2}
		\begin{tabular}{|l|c|c|c|c|c|}
			\hline
			$\tau$ &  0.5 & 0.4 & 0.3 & 0.2& 0.1 \\
			\hline
			\text{Correct} 1 & 4  & 8 &  9 & 14 &17    \\ \hline
			\text{Correct} 0 & 648 & 637 & 636  & 634 & 582   \\ \hline
			\text{Wrong} 1 & 32  & 27 & 22  & 26 &  19  \\ \hline
			\text{Wrong} 0 & 0  & 11 & 12  & 14 &  66  \\ \hline
			\text{TCR} & 95.32\%  &  94.29\%  &  94.44\%  & 95.03\% &  87.57\%  \\
			\hline 
		\end{tabular}
	\end{table}
\end{enumerate}
对比以上两个模型，我们可以得到以下结论：
\begin{enumerate}[a.]
	\item 对于全模型，降低 $\tau$ 的值可以提高1预测的准确性，但随之而来的代价是0预测错误率提高。具体来说，$\tau$ 值从0.5下降到0.2时， 预测的结果变化不大，但是从0.2将到0.1时，预测结果有着较大的变化，1的预测正确率显著提高，但是随之而来的代价是总体预测正确率的下降。
	\item 对于降阶模型，同全模型一样随着$\tau$的降低，1预测的准确性提高，0预测的准确性降低。但是，同全模型不同的是，随着$\tau$的降低，
	模型的预测结果变化比较均匀。 
\end{enumerate}

\section{方法}

\subsection{数据收集与预处理}

蛋白质互作网络数据来自STRING数据库，我们从人类蛋白的相互作用中筛选了作用模式为物理相互作用（physical）的蛋白对，用于后续模型训练。
蛋白亚细胞的定位和氨基酸序列数据来自UniProtKB/Swiss-Prot数据库：
其中，对于亚细胞定位注释，我们只保留存在文献支持的条目，经过滤后的定位注释有213种，大部分定位对应的蛋白都非常少（TODO: figure），我们只取蛋白数最多的11种亚细胞定位，包括细胞核(Nucleus)，细胞质(Cytoplasm)，细胞膜(Cell membrane)，膜(Membrane)，外泌(Secreted)，细胞骨架(Cytoskeleton)，细胞凸起(Cell projection)，内质网膜(Endoplasmic reticulum membrane)，细胞连接(Cell junction)，线粒体(Mitochondrion)和高尔基体(Golgi apparatus)；需要说明的是，这些亚细胞定位并不是互斥的，同一个蛋白可能会在多个位置出现并发挥功能；
对于氨基酸序列，我们丢掉了含有特殊氨基酸（硒半胱氨酸，Selenocysteine, U）的序列，所有序列只包含20种基本氨基酸；此外，相似序列在训练集和测试集中分别出现可能导致模型的预测性能被高估，因此我们使用cd-hit工具对序列进行了聚类，相似度高于90\%的序列作为一个类，只取其中一条序列作为代表，保证剩下的序列两两之间相似性低于90\%；最后，为了加快计算速度，我们只保留长度小于2000氨基酸的序列（TODO: figure）；
经过上述筛选之后，同时满足亚细胞定位和序列过滤条件，且在STRING蛋白互作网络中的蛋白共有7591条，构成模型评估的核心数据集。

\subsection{模型构建}

蛋白的亚细胞定位与其氨基酸序列有关，因此我们首先从氨基酸序列抽取可用的数据特征，一种传统特征提取方式是kmer频率(TODO: lix?)；
参考现有基于CNN的生物序列预测模型 (Alipanahi, B. et al., 2015. Predicting the sequence specificities of DNA- and RNA-binding proteins by deep learning. Nature Biotechnology, 33(8), pp.831–838. Zhou, J. & Troyanskaya, O.G., 2015. Predicting effects of noncoding variants with deep learning-based sequence model. Nature Methods, 12(10), pp.931–934.)，我们也尝试使用CNN来学习氨基酸序列中的motif，首先，每种氨基酸被编码成20维的one-hot向量（第i维为1代表这是第i种氨基酸），在此基础上，长度为L的蛋白（由L个氨基酸组成），可以表示成L*20的矩阵，类比图像数据相当于蛋白是有20个通道的一维“图像”；由于计算效率的原因，CNN一般要求输入具有相同的大小，而蛋白序列的长度是不确定的，因此我们以数据集中最长的蛋白为标准（长度<2000，见“数据收集与预处理”），在其他蛋白末尾补零，得到相同长度作为卷积输入，进行"valid"模式的卷积，并使用ReLU激活函数，只输出正值；在池化层，再按照序列长度屏蔽补零位置的信号（主要屏蔽补零边界上的信号），池化策略方面，我们使用全局最大和全局求和的折中，取k个最大值求和作为输出，这样使得池化输出不会受到蛋白长度的影响，同时又能反映相同序列motif多次出现的剂量效应。
我们尝试了两种基于CNN的蛋白序列特征提取方法，第一种是在训练集上进行有监督学习，第二种是在更大的无标签数据集上进行无监督学习；有监督学习比较常规，在池化层后面使用全连接层进行亚细胞定位预测，然后将倒数第二个全连接层的输出作为提取到的序列特征；无监督学习策略类似于噪音对比估计(noise contrastive estimation)，具体做法是按照数据集中20种氨基酸的出现频率，随机生成氨基酸序列，随机序列的长度和真实序列一一对应，然后让CNN学习区分真实的蛋白序列和随机序列，这样我们期望CNN的卷积层能抓取到只有真实蛋白中高频出现的序列motif，可能与蛋白的生物学功能有关，其中就包括亚细胞定位，为了抓取尽可能多的motif，我们使用了较多卷积核，这样CNN学到的卷积核之间可能存在相关性，因此我们在CNN训练完成之后再使用一个变分自编码器VAE (Kingma, D.P. & Welling, M., 2013. Auto-Encoding Variational Bayes. arXiv.org, stat.ML.) 去拟合CNN池化层的输出，将VAE的隐变量作为最终序列特征，期望能得到信息更紧密的序列表示，具体来说，我们使用Gamma分布作为生成分布，模型的损失函数如下：
$$-\mathcal L(\theta, \phi) = \mathbb E_{z \sim q(z|x;\phi)} [\log p(x|z;\theta)] - KL(q(z|x;\phi) \parallel p(z))$$
其中，
$$p(z)=\mathcal N(0, I)$$
$$q(z|x;\phi)=\mathcal N(\mu_x, diag(\sigma_x^2))$$
$$KL(q(z|x;\phi) \parallel p(z)) = \frac 1 2 \sum_i (\mu_{i,x}^2 + \sigma_{i,x}^2 - \log \sigma_{i,x}^2 - 1)$$
$$\log p(x|z;\theta)=\alpha_z \cdot\ log \beta - \log \Gamma(\alpha_z) + (\alpha_z - 1) \cdot \log x - \beta \cdot x$$
后验分布的$\mu_x$, $\sigma_x^2$由$\theta$参数化的编码器网络实现，生成分布的$\alpha_z$由$\phi$参数化的解码器网络实现，$\beta$固定为定值，对$q(z|x;\phi)$的期望用reparameterization trick来计算;
为了公平，有监督和无监督序列特征都设定为100维。

在上面得到的数据特征基础上，我们分别用全连接层和图卷积层构建预测网络，最终输出$p \in \mathbb R^J$各类别为阳性的概率，这里各类别没有互斥性，有监督损失函数使用的是$J$个二分类交叉熵的和：
$$\mathcal L(\theta) = \sum_i^N w_i \sum_j^{J} y_j\cdot \log p_j + (1-y_j)\cdot \log (1-p_j) $$
其中$w_i$是样本权重，为了平衡不同类别的样本，我们按照训练集中阳性和阴性的比例来给两种样本分别加权：
$$w_i=y_i \cdot (\frac N^++N^- 2N^+) + (1-y_i) \cdot (\frac N^++N^- 2N^-)$$

最后，我们使用5折交叉验证来进行模型评估，对于需要验证集的模型，从训练集中再随机抽取10\%作为验证集。

此外，为了评估蛋白质相互作用信息与亚细胞定位的关系，我们建立了一个不需要任何特征，仅依赖于蛋白质相互作用信息的预测模型，称之为GN（graph-neighbor）模型。对训练集或测试集中的任一蛋白质，我们根据训练集中与它有相互作用的蛋白质中具有某定位的蛋白质所占的比例来作为它具有该定位的概率，如果该蛋白质在训练集中没有邻居，则以整个训练集中具有该定位的蛋白质所占的比例作为其具有该定位的概率。



采用 Single-Index 模型较GLM相比已经有了很大的进步，我们继续尝试一些机器学习的方法对数据进行建模。

支持向量机（SVM）是一种应用广泛的分类方法，其原理是在高维或无限维空间中构造超平面或超平面集合，使得分类边界距离最近的训练数据点尽可能的远，如下图所示：
\begin{figure}[H]
	\centering\includegraphics[scale=0.3]{aic-m1.pdf}
\end{figure}
\begin{itemize}
	\item 称训练样本是线性可分的，如果存在决策超平面 $w\cdot x+b=0 $，使得以
	下两式成立 ：
	$$w\cdot x_{i}+b\geq 1 \quad\text{for}\quad y_{i}=1 $$
	$$w\cdot x_{i}+b\leq -1 \quad\text{for\quad} y_{i}=-1 $$
	\item 称决策超平面是最优的，如果训练集到该超平面的最小距离最大。
\end{itemize}

线性最优分离超平面相当于在约束条件 $y_{i}(w\cdot x_{i}+b) \geq 1$ 下，找到 $\frac{2}{|w|}$ 的最大值。此最优化问题等价于在约束条件 $y_{i}(w\cdot x_{i}+b) \geq 1$ 下，求$ \frac{||w ||^{2}}{2}$	的最小值。我们可以采用ADMM算法对此问题进行求解。即
$$\min \frac{1}{2}  \sum_{i=1}^{n}\sum_{j=1}^{n} \alpha_{i}\alpha_{j}y_{i}y_{j}x_{i}^{T}x_{j} - \sum_{i=1}^{n}\alpha_{i}$$
$$\sum_{i=1}^{n}\alpha_{i}y_{i}=0,\quad \alpha_{i} \geq 0,\quad 1\leq i \leq n $$

尽管原始问题可能是在有限维空间中陈述的，但用于区分的集合在该空间中往往线性不可分。为此，有人提出将原有限维空间映射到维数高得多的空间中，在该空间中进行分离可能会更容易，这就是Kernel-SVM算法。下图用一个简单的例子生动形象的描述了这一算法的思想：
\begin{figure}[H]
	\centering\includegraphics[scale=0.2]{aic-m2.pdf}
\end{figure}

线性SVM的算法求解依赖向量之间的内积$x_{i}^{T}x_{j}$, 而Kernel-SVM的算法是用一个映射$\phi:x\rightarrow\phi(x)$ 把数据映射到高维空间，之后用核函数的形式替代两个向量的内积，即
$$K(x_{i},x_{j})=\phi(x_{i})^{T}\phi(x_{j}) $$

这里的“Kernel”与我们在非参数统计课程中所学的“Kernel-Smoothing”、\\“Kernel-Estimation”中的“Kernel”意义相同。非参数方法中的“Kernel”，实际上是距离函数，$\frac{1}{n}\sum K_{h}(x_{i}-x)$ 就是$x$附近点到$x$距离的加权和。而内积就是希尔伯特空间中对距离的推广。此问题用数学语言描述出来即为：在由$K$作为再生核生成的再生希尔伯特空间(RKHS)中找到合适的函数，使得变换后的数据可以被该函数分割成两部分。因为我们优化问题的空间是一个函数空间(RKHS),所以这是一种非参数方法。

在此例中，我们采用多项式核函数，即$K(x,z)=<x,z> $, 其他常用的核函数还有：
\begin{itemize}
	\item 径向基函数(RBF): $K(x,z)=e^{-||x-z||^{2}/2\sigma} $
	\item 双曲正切核函数：$K(x,z)=tanh(kx^{T}y+\theta) $
\end{itemize}

对于此问题的求解，只需把线性情况下的内积换成核函数，即：
$$\min \frac{1}{2}  \sum_{i=1}^{n}\sum_{j=1}^{n} \alpha_{i}\alpha_{j}y_{i}y_{j}k(x_{i},x_{j}) - \sum_{i=1}^{n}\alpha_{i}$$
$$\sum_{i=1}^{n}\alpha_{i}y_{i}=0,\quad \alpha_{i} \geq 0,\quad 1\leq i \leq n $$
采用此方法，得到的结果648个0全部分类正确，36个1分类正确6个；可见远远优于之前提出的统计模型方法，这是现阶段我们得到的最好结果。

\section{实验结果}

\section{总结与讨论}
在这篇文章中，我们对684家上市公司的股票进行ST预测，先采用GLM模型后发现该数据呈现非参数性，故采用半参数的Single-Index的模型再次对数据进行拟合，得到了比GLM较好的结果；最后采用机器学习之Kernel-SVM算法再次对数据进行分析。由于我们所选取的数据中1的值较少，再加上中国股市受很多方面因素特别是政策和国内形势的影响，造成了我们对1的预测成功率最高只有50\%。\\

但是通过上述过程的分析，我们不难发现采用非参数的方法可以更好的拟合模型，而付出的代价则是算法时间复杂度的增加。本例中有7个协变量，若采用普通非参数的方法很难得到有效的求解，故采用Single-Index进行降维；并且，采用Single-Index得到的结果也更加灵活，我们可以采用降低阈值的方法来估计出更多正确的1。总之，通过对这个问题的探究，我们对比了参数模型和非参数模型的优劣，学习掌握了许多对之后的学习研究有帮助的方法;特别是第一次处理真实数据的经历让我们意识到了理论应用于实践过程中的鸿沟，想必也会为将来的学习工作提供宝贵的经验。
\cite{kipf2016semi}


%%%%%%%  参考文献
\nocite{*}   % 显示参考文献列表
\bibliographystyle{IEEEtranN}
\bibliography{references}




\end{document}

